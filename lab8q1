import numpy as np
from collections import Counter
import math
 
class DecisionTree:
    def __init__(self):
        pass
    def entropy(self, labels):
        label_counts = Counter(labels)
        num_labels = len(labels)
        entropy = 0
        for count in label_counts.values():
            prob = count / num_labels
            entropy -= prob * math.log(prob, 2)
        return entropy
    def information_gain(self, data, labels, feature_idx):
        # Calculate parent entropy
        parent_entropy = self.entropy(labels)
        # Calculate weighted sum of child entropies
        unique_values = np.unique(data[:, feature_idx])
        children_entropy = 0
        for value in unique_values:
            child_indices = np.where(data[:, feature_idx] == value)[0]
            child_labels = labels[child_indices]
            children_entropy += (len(child_labels) / len(labels)) * self.entropy(child_labels)
        # Calculate information gain
        information_gain = parent_entropy - children_entropy
        return information_gain
    def find_root_node(self, data, labels, feature_names):
        num_features = data.shape[1]
        best_feature_idx = None
        max_information_gain = -float('inf')
        for feature_idx in range(num_features):
            information_gain = self.information_gain(data, labels, feature_idx)
            if information_gain > max_information_gain:
                max_information_gain = information_gain
                best_feature_idx = feature_idx
        return best_feature_idx, feature_names[best_feature_idx]

# Example usage:
def load_data(dataset_path):
    data = np.genfromtxt(dataset_path, delimiter=',', dtype=str)
    features = data[0, :-1]
    labels = data[1:, -1]
    data = data[1:, :-1]
    return data, labels, features
 
dataset_path = r"C:\Users\heman\OneDrive\Documents\SEM_4\ML\Lab\8\Unemployment_in_India.csv"  
data, labels, feature_names = load_data(dataset_path)
 
dt = DecisionTree()
root_node_idx, root_node_name = dt.find_root_node(data, labels, feature_names)
print("Root node of the Decision Tree:")
print("Feature index:", root_node_idx)
print("Feature name:", root_node_name)
